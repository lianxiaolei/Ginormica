{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import skimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, BatchNormalization, Reshape\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = '0123456789+-*/=()'\n",
    "width, height, n_len, n_class = 400, 80, 14, len(characters) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    ds = '0123456789'\n",
    "    ts = ['{}{}{}{}{}', '({}{}{}){}{}', '{}{}({}{}{})']\n",
    "    os = '+-*/'\n",
    "    # os = ['+', '-', 'times', 'div']\n",
    "    cs = [random.choice(ds) if x % 2 == 0 else random.choice(os) for x in range(5)]\n",
    "    return random.choice(ts).format(*cs)\n",
    "\n",
    "\n",
    "def get_img_by_char(char, base_path='./pre_ocr'):\n",
    "    \"\"\"\n",
    "    get a img by giving char\n",
    "    :param char:\n",
    "    :param base_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    opdict = {'+': 10, '-': 11, '*': 12, '/': 13, '=': 14, '(': 15, ')': 16}\n",
    "    if char in opdict.keys():\n",
    "        char = opdict[char]\n",
    "    path = os.path.join(base_path, str(char))\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    rdm = random.randint(0, len(files) - 1)\n",
    "    \n",
    "    if rdm >= len(files):\n",
    "        print(path, len(files), rdm)\n",
    "        \n",
    "    file = files[rdm]\n",
    "    path = os.path.join(path, file)\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "def get_sequence_img(chars):\n",
    "    x = get_img_by_char(chars[0])\n",
    "    for i in range(1, len(chars)):\n",
    "        x = np.hstack([x, get_img_by_char(chars[i])])\n",
    "    x = cv2.resize(x, (400, 80))\n",
    "#     x = skimage.util.random_noise(x, mode='gaussian', clip=True)\n",
    "#     print('get_sequence_img output')\n",
    "#     plt.imshow(x)\n",
    "#     plt.show()\n",
    "#     print (chars, x.shape)\n",
    "    return x\n",
    "\n",
    "\n",
    "def gen(batch_size=128, gene=4):\n",
    "    X = np.zeros((batch_size, width, height, 1), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, n_len), dtype=np.uint8)\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            random_str = ''.join([random.choice(characters) for j in range(n_len)])\n",
    "#             random_str = '60/3=20'\n",
    "            tmp = np.array(get_sequence_img(random_str))\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            tmp = tmp.transpose(1, 0, 2)\n",
    "            \n",
    "            X[i] = tmp\n",
    "            y[i] = [characters.find(x) for x in random_str]\n",
    "            \n",
    "        yield [X, y, np.ones(batch_size) * rnn_length, np.ones(batch_size) * n_len], np.ones(batch_size)\n",
    "\n",
    "        \n",
    "def gen_new(batch_size=128, gene=4):\n",
    "    X = np.zeros((batch_size, width, height, 1), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, n_len), dtype=np.uint8)\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            random_str = ''.join([random.choice(characters) for j in range(n_len)])\n",
    "#             random_str = '60/3=20'\n",
    "            tmp = np.array(get_sequence_img(random_str))\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            tmp = tmp.transpose(1, 0, 2)\n",
    "            \n",
    "            X[i] = tmp\n",
    "            y[i] = [characters.find(x) for x in random_str]\n",
    "        \n",
    "        i = 0\n",
    "        XX = None\n",
    "        yy = None\n",
    "        for batch in datagen.flow(X, y, batch_size=batch_size):\n",
    "#             print(batch[0].shape, batch[1].shape)\n",
    "            \n",
    "            if not type(XX) == np.ndarray:\n",
    "                XX = batch[0]\n",
    "                yy = batch[1]\n",
    "            else:\n",
    "                XX = np.concatenate([XX, batch[0]], axis=0)\n",
    "                yy = np.concatenate([yy, batch[1]], axis=0)\n",
    "            \n",
    "            i += 1\n",
    "            if i >= gene:\n",
    "                break\n",
    "        yield [XX, yy, np.ones(batch_size * gene) * rnn_length, np.ones(batch_size * gene) * n_len], np.ones(batch_size * gene)\n",
    "\n",
    "        \n",
    "y = None\n",
    "y_val = None\n",
    "\n",
    "\n",
    "def gen_single(batch_size=128, gene=4, flag=None):\n",
    "    X = np.zeros((batch_size, width, height, 3), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, n_len), dtype=np.uint8)\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            random_str = ''.join([random.choice(characters) for j in range(n_len)])\n",
    "#             random_str = '60/3=20'\n",
    "            tmp = np.array(get_sequence_img(random_str))\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            tmp0 = np.copy(tmp)\n",
    "            tmp = np.concatenate([tmp, tmp0], axis=2)\n",
    "            tmp = np.concatenate([tmp, tmp0], axis=2)\n",
    "            tmp = tmp.transpose(1, 0, 2)\n",
    "            \n",
    "            X[i] = tmp\n",
    "            y[i] = [characters.find(x) for x in random_str]\n",
    "        \n",
    "        yield X\n",
    "        \n",
    "\n",
    "def data_single(batch_size=128):\n",
    "    X = np.zeros((batch_size, width, height, 3), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, n_len), dtype=np.uint8)\n",
    "    for i in range(batch_size):\n",
    "        random_str = ''.join([random.choice(characters) for j in range(n_len)])\n",
    "        tmp = np.array(get_sequence_img(random_str))\n",
    "        tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "        tmp0 = np.copy(tmp)\n",
    "        tmp = np.concatenate([tmp, tmp0], axis=2)\n",
    "        tmp = np.concatenate([tmp, tmp0], axis=2)\n",
    "        tmp = tmp.transpose(1, 0, 2)\n",
    "\n",
    "        X[i] = tmp\n",
    "        y[i] = [characters.find(x) for x in random_str]\n",
    "        \n",
    "    return X, y\n",
    "    \n",
    "    \n",
    "YY = None\n",
    "YY_val = None\n",
    "\n",
    "\n",
    "def gen_new_single(batch_size=128, gene=4, flag=None):\n",
    "    X = np.zeros((batch_size, width, height, 3), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, n_len), dtype=np.uint8)\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            random_str = ''.join([random.choice(characters) for j in range(n_len)])\n",
    "#             random_str = '60/3=20'\n",
    "            tmp = np.array(get_sequence_img(random_str))\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            tmp0 = np.copy(tmp)\n",
    "            tmp = np.concatenate([tmp, tmp0], axis=2)\n",
    "            tmp = np.concatenate([tmp, tmp0], axis=2)\n",
    "            tmp = tmp.transpose(1, 0, 2)\n",
    "            \n",
    "            X[i] = tmp\n",
    "            y[i] = [characters.find(x) for x in random_str]\n",
    "        \n",
    "        i = 0\n",
    "        XX = None\n",
    "        yy = None\n",
    "        for batch in datagen.flow(X, y, batch_size=batch_size):\n",
    "#             print(batch[0].shape, batch[1].shape)\n",
    "            \n",
    "            if not type(XX) == np.ndarray:\n",
    "                XX = batch[0]\n",
    "                yy = batch[1]\n",
    "            else:\n",
    "                XX = np.concatenate([XX, batch[0]], axis=0)\n",
    "                yy = np.concatenate([yy, batch[1]], axis=0)\n",
    "            \n",
    "            i += 1\n",
    "            if i >= gene:\n",
    "                break\n",
    "        if flag == None:\n",
    "            YY = yy\n",
    "        else:\n",
    "            YY_val = yy\n",
    "        yield XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(batch_size=128, steps=10):\n",
    "    batch_acc = 0\n",
    "    generator = gen(batch_size)\n",
    "    for i in range(steps):\n",
    "        [X_test, y_test, _, _], _  = next(generator)\n",
    "        y_pred = base_model.predict(X_test)\n",
    "        shape = y_pred[:,2:,:].shape\n",
    "        ctc_decode = K.ctc_decode(y_pred[:,2:,:], input_length=np.ones(shape[0])*shape[1])[0][0]\n",
    "        out = K.get_value(ctc_decode)[:, :n_len]\n",
    "        if out.shape[1] == n_len:\n",
    "            batch_acc += (y_test == out).all(axis=1).mean()\n",
    "    return batch_acc / steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "\n",
    "class Evaluator(Callback):\n",
    "    def __init__(self):\n",
    "        self.accs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc = evaluate(steps=20)*100\n",
    "        self.accs.append(acc)\n",
    "        print('')\n",
    "        print('acc: %f%%' % acc)\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input((width, height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='./vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.pooling.MaxPooling2D object at 0x7fceb83723c8>\n",
      "Tensor(\"block5_pool_2/MaxPool:0\", shape=(?, 12, 2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[-1])\n",
    "print(model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_shape = model.output.get_shape().as_list()\n",
    "# pred = model.predict_generator(gen_single(32), 10)\n",
    "X, y = data_single()\n",
    "pred = model.predict(X)\n",
    "\n",
    "# val_pred = model.predict_generator(gen_single(32), 8)\n",
    "X_val, y_val = data_single(batch_size=64)\n",
    "pred_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 12, 2, 512) 12 1024\n"
     ]
    }
   ],
   "source": [
    "conv_shape = pred.shape\n",
    "rnn_length = conv_shape[1]\n",
    "rnn_dimen = conv_shape[2] * conv_shape[3]\n",
    "print(conv_shape, rnn_length, rnn_dimen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 12, 1024)\n",
      "(?, 12, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "_, h, w, d = pred.shape\n",
    "input_tensor = Input((h, w, d))\n",
    "x = input_tensor\n",
    "x = Reshape(target_shape=(rnn_length, rnn_dimen))(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Dense(128, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "rnn_size = 128\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(x)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', \n",
    "             name='gru1_b')(x)\n",
    "gru1_merged = add([gru_1, gru_1b])\n",
    "\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', \n",
    "             name='gru2_b')(gru1_merged)\n",
    "x = concatenate([gru_2, gru_2b])\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(n_class, kernel_initializer='he_normal', activation='softmax')(x)\n",
    "base_model = Model(input=input_tensor, output=x)\n",
    "\n",
    "\n",
    "labels = Input(name='the_labels', shape=[n_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=(1,), dtype='int64')\n",
    "label_length = Input(name='label_length', shape=(1,), dtype='int64')\n",
    "loss_out = Lambda(ctc_lambda_func, name='ctc')([base_model.output, labels, input_length, label_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbn = Model(inputs=(input_tensor, labels, input_length, label_length), outputs=loss_out)\n",
    "vbn.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-fe736135feb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrnn_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrnn_dimen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[1;32m   1486\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                                                    self._feed_output_names)\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[0;32m-> 1486\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "vbn.fit([pred, y, np.ones(len(X)) * rnn_length, np.ones(len(X) * rnn_dimen) ], nb_epoch=50, batch_size=32, validation_data=(pred_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-217886a437b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'the_labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlabel_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "md = Sequential()\n",
    "md.add(Dense(128, input_shape=(12, 2, 512), activation='relu', kernel_initializer='he_normal'))\n",
    "md.add(Activation('relu'))\n",
    "\n",
    "rnn_size = 128\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1_b')\n",
    "# # gru1_merged = add([gru_1, gru_1_b])\n",
    "# md.add(Concatenate([gru_1, gru_1b]))\n",
    "\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2_b')\n",
    "\n",
    "md.add(Dropout(0.25))\n",
    "md.add(Dense(n_class, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "labels = Input(name='the_labels', shape=[n_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=(1,), dtype='int64')\n",
    "label_length = Input(name='label_length', shape=(1,), dtype='int64')\n",
    "loss_out = Lambda(ctc_lambda_func, name='ctc')([base_model.output, labels, input_length, label_length])\n",
    "\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "md.fit(pred, YY,\n",
    "          nb_epoch=50, batch_size=32,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "md.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_40/truediv:0' shape=(?, 12, 18) dtype=float32>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
