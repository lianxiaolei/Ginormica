{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_new(flag, path='../../../../assets/brand_images'):\n",
    "    \"\"\"\n",
    "    read the dataset，dir format must be: ./train/, ./train.txt, ./test/, ./test.txt\n",
    "    :param flag: 'train' or 'test'\n",
    "    \"\"\"\n",
    "    content = open(os.path.join(path, '%s.txt' % flag))\n",
    "    \n",
    "    imgs = []\n",
    "    labels = []\n",
    "\n",
    "    lines = content.readlines()\n",
    "    # tqdm is the progress bar, please install it with \"pip install tqdm\". if u wan't, you can replace tqdm(lines) with lines.\n",
    "    for i in tqdm(lines):\n",
    "        fname, y = i.replace('\\n', '').split(' ')\n",
    "        y = int(y)\n",
    "        \n",
    "        x = os.path.join(path, flag, fname)\n",
    "        \n",
    "        imgs.append(x)\n",
    "        labels.append(y)\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 掏粪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 2725/2725 [00:00<00:00, 170355.31it/s]\n"
     ]
    }
   ],
   "source": [
    "xx, yy = read_data_new('train')\n",
    "# list to tensor\n",
    "filelist_tensor = tf.convert_to_tensor(xx, dtype=tf.string)\n",
    "labellist_tensor = tf.convert_to_tensor(yy, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = [0] * len(yy)\n",
    "testfilesize = int(len(yy) / 5)\n",
    "partitions[:testfilesize] = [1] * testfilesize\n",
    "random.shuffle(partitions)\n",
    "\n",
    "# dynamic partition for split the train and test\n",
    "trainfilelist, testfilelist = tf.dynamic_partition(data=filelist_tensor,\n",
    "                                                  partitions=partitions,\n",
    "                                                  num_partitions=2)\n",
    "\n",
    "trainlabellist, testlabellist = tf.dynamic_partition(data=labellist_tensor,\n",
    "                                                    partitions=partitions,\n",
    "                                                    num_partitions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image width and height\n",
    "IMG_WIDTH = 600\n",
    "IMG_HEIGHT = 300\n",
    "\n",
    "def image_operate(input_queue):\n",
    "    \"\"\"\n",
    "    image operattions consist of file name to img, resize\n",
    "    \"\"\"\n",
    "    label = input_queue[1]\n",
    "    # get contents from file\n",
    "    print(input_queue[0])\n",
    "    contents = tf.read_file(input_queue[0])\n",
    "    # decode image by its format\n",
    "    image = tf.image.decode_jpeg(contents)\n",
    "    # resize size argument must be [width, height]\n",
    "    image = tf.image.resize_images(images=image,\n",
    "                                   size=[IMG_WIDTH, IMG_HEIGHT])\n",
    "    image = tf.reshape(image,tf.stack([IMG_WIDTH, IMG_HEIGHT, 3]))\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs \n",
    "train_input_queue = tf.train.slice_input_producer(tensor_list=[trainfilelist, trainlabellist],\n",
    "                                                  shuffle=False,  # whether shuffle the data\n",
    "                                                  num_epochs=1  # determines the number of times to output total data\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_producer/Gather:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = image_operate(train_input_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'batch:0' shape=(20, 600, 300, 3) dtype=float32>,\n",
       " <tf.Tensor 'batch:1' shape=(20,) dtype=int16>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size \n",
    "BATCH_SIZE = 20\n",
    "\n",
    "train_batch = tf.train.batch(tensors=[train_x , train_y], \n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_threads=2,\n",
    "                            )\n",
    "train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "batch 2 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "batch 3 [2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "batch 4 [3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "batch 5 [4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "batch 6 [5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6]\n",
      "batch 7 [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "batch 8 [6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "batch 9 [8 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "batch 10 [8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "batch 11 [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      "batch 12 [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11]\n",
      "batch 13 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\n",
      "batch 14 [11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12]\n",
      "batch 15 [12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13]\n",
      "batch 16 [13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14]\n",
      "batch 17 [14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]\n",
      "batch 18 [15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16]\n",
      "batch 19 [17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17]\n",
      "batch 20 [18 18 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18]\n",
      "batch 21 [18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19]\n",
      "batch 22 [19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20 20 20 20 20]\n",
      "batch 23 [20 20 20 20 20 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21]\n",
      "batch 24 [21 21 21 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22]\n",
      "batch 25 [22 22 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23]\n",
      "batch 26 [23 23 24 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24]\n",
      "batch 27 [24 24 24 24 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25]\n",
      "batch 28 [25 25 25 25 25 25 25 25 25 25 26 26 26 26 26 26 26 26 26 26]\n",
      "batch 29 [26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 27]\n",
      "batch 30 [27 27 27 27 27 27 27 27 28 27 28 28 28 28 28 28 28 28 28 28]\n",
      "batch 31 [28 28 28 28 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 29]\n",
      "batch 32 [29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30 30 30]\n",
      "batch 33 [30 30 30 30 30 30 31 31 31 31 31 31 31 31 31 31 31 31 31 31]\n",
      "batch 34 [31 31 31 31 31 31 31 31 31 32 31 32 32 32 32 32 32 32 32 32]\n",
      "batch 35 [32 32 32 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33]\n",
      "batch 36 [33 33 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34]\n",
      "batch 37 [34 34 34 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35]\n",
      "batch 38 [35 35 35 35 35 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36]\n",
      "batch 39 [36 36 36 36 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37]\n",
      "batch 40 [37 37 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38]\n",
      "batch 41 [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39]\n",
      "batch 42 [39 39 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40]\n",
      "batch 43 [40 40 40 40 40 40 41 41 41 41 41 41 41 41 41 41 41 41 41 41]\n",
      "batch 44 [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 42 42 42]\n",
      "batch 45 [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 43 43]\n",
      "batch 46 [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 44 44 44]\n",
      "batch 47 [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44]\n",
      "batch 48 [45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45]\n",
      "batch 49 [45 45 45 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46]\n",
      "batch 50 [47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47]\n",
      "batch 51 [47 47 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 49]\n",
      "batch 52 [49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 50]\n",
      "batch 53 [50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 51]\n",
      "batch 54 [51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51]\n",
      "batch 55 [52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52]\n",
      "batch 56 [52 52 52 52 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53]\n",
      "batch 57 [53 53 53 53 53 53 53 54 54 54 54 54 54 54 54 54 54 54 54 54]\n",
      "batch 58 [54 54 54 54 54 54 54 54 55 55 55 55 55 55 55 55 55 55 55 55]\n",
      "batch 59 [55 55 55 55 55 55 55 55 55 55 55 56 56 56 56 56 56 56 56 56]\n",
      "batch 60 [56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56]\n",
      "batch 61 [56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 57]\n",
      "batch 62 [57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57]\n",
      "batch 63 [57 57 57 57 57 57 57 58 58 58 58 58 58 58 58 58 58 58 58 58]\n",
      "batch 64 [58 58 58 58 58 58 59 58 59 59 59 59 59 59 59 59 59 59 59 59]\n",
      "batch 65 [59 59 59 59 59 59 59 59 59 59 59 59 59 60 60 60 60 60 60 60]\n",
      "batch 66 [60 60 60 60 60 60 60 60 60 60 60 60 61 61 61 61 61 61 61 61]\n",
      "batch 67 [61 61 61 61 61 61 61 61 61 61 61 61 61 62 62 62 62 62 62 62]\n",
      "batch 68 [62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62]\n",
      "batch 69 [62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 63 63]\n",
      "batch 70 [63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63]\n",
      "batch 71 [63 63 63 63 63 63 63 63 63 63 63 63 63 64 64 64 64 64 64 64]\n",
      "batch 72 [64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64]\n",
      "batch 73 [64 64 64 64 64 64 65 65 65 65 65 65 65 65 65 65 65 65 65 65]\n",
      "batch 74 [65 65 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66]\n",
      "batch 75 [66 66 66 66 66 67 67 67 67 67 67 67 67 67 67 67 67 67 67 68]\n",
      "batch 76 [68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 69 68]\n",
      "batch 77 [69 69 69 69 69 69 69 69 69 69 69 69 69 69 70 70 70 70 70 70]\n",
      "batch 78 [70 70 70 70 70 70 70 70 70 70 71 71 71 71 71 71 71 71 71 71]\n",
      "batch 79 [71 71 71 71 72 72 72 72 72 72 72 72 72 72 72 72 72 72 73 73]\n",
      "batch 80 [73 73 73 73 73 73 73 73 73 73 73 73 73 73 74 74 74 74 74 74]\n",
      "batch 81 [74 74 74 74 74 74 74 74 74 74 74 74 74 75 75 75 75 75 75 75]\n",
      "batch 82 [75 75 75 75 75 75 75 75 75 75 76 76 76 76 76 76 76 76 76 76]\n",
      "batch 83 [76 76 76 76 76 76 76 76 76 76 76 76 76 76 77 77 77 77 77 77]\n",
      "batch 84 [77 77 77 77 77 77 77 78 77 78 78 78 78 78 78 78 78 78 78 78]\n",
      "batch 85 [78 78 78 78 78 78 78 78 78 78 78 79 79 79 79 79 79 79 79 79]\n",
      "batch 86 [79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79]\n",
      "batch 87 [79 79 79 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80]\n",
      "batch 88 [81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 82]\n",
      "batch 89 [82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 83 83 83]\n",
      "batch 90 [83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 84 84 84 84 84]\n",
      "batch 91 [84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 85 85 85 85]\n",
      "batch 92 [85 85 85 85 85 85 85 85 85 85 85 85 86 86 86 86 86 86 86 86]\n",
      "batch 93 [86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86]\n",
      "batch 94 [87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87]\n",
      "batch 95 [87 87 87 87 87 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88]\n",
      "batch 96 [88 88 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89]\n",
      "batch 97 [89 90 89 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90]\n",
      "batch 98 [90 90 90 90 90 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91]\n",
      "batch 99 [91 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92]\n",
      "batch 100 [92 92 92 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93]\n",
      "batch 101 [93 93 93 93 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94]\n",
      "batch 102 [94 94 94 94 94 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95]\n",
      "batch 103 [95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95]\n",
      "batch 104 [95 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96]\n",
      "batch 105 [96 96 96 96 96 96 96 96 96 96 96 96 96 96 97 97 97 97 97 97]\n",
      "batch 106 [97 97 97 97 97 97 97 97 97 98 98 98 98 98 98 98 98 98 98 98]\n",
      "batch 107 [98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98]\n",
      "batch 108 [98 98 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99]\n",
      "batch 109 [ 99  99  99  99  99  99  99  99  99 100 100 100 100 100 100 100 100 100\n",
      " 100 100]\n",
      "Done training -- epoch limit reached\n"
     ]
    }
   ],
   "source": [
    "ep = 0\n",
    "with tf.Session() as sess:\n",
    "    ini_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(ini_op)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    try:  \n",
    "        while not coord.should_stop():\n",
    "            \n",
    "            x, y_ = sess.run(train_batch)\n",
    "            #  you can doing sth in there with the batch data x, y_\n",
    "            ep += 1\n",
    "            print('batch %s' % ep, y_)\n",
    "\n",
    "#             print(2 / 0)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')  \n",
    "    finally:  \n",
    "        coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            rotation_range=0.2,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "global _gen_temp\n",
    "_gen_temp = 0\n",
    "sess = tf.Session()\n",
    "\n",
    "def data_gen(batch_size=128, gene=4):\n",
    "    global _gen_temp\n",
    "    while True:\n",
    "        label_list = yy[_gen_temp * batch_size: min((_gen_temp + 1) * batch_size, len(yy) - 1)]\n",
    "        file_list = xx[_gen_temp * batch_size: min((_gen_temp + 1) * batch_size, len(xx) - 1)]\n",
    "        _gen_temp += 1\n",
    "        \n",
    "        X_ = []\n",
    "        for fname in file_list:\n",
    "            img = cv2.imread(fname)\n",
    "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            X_.append(img.tolist())\n",
    "        X_ = np.array(X_)\n",
    "        y_ = np.array(label_list)\n",
    "        \n",
    "        i = 0\n",
    "        X = None\n",
    "        y = None\n",
    "        \n",
    "        for batch in datagen.flow(X_, y_, batch_size=batch_size):            \n",
    "            if not type(X) == np.ndarray:\n",
    "                X = batch[0]\n",
    "                y = batch[1]\n",
    "            else:\n",
    "                X = np.concatenate([X, batch[0]], axis=0)\n",
    "                y = np.concatenate([y, batch[1]], axis=0)\n",
    "            \n",
    "            i += 1\n",
    "            if i >= gene:\n",
    "                break\n",
    "        \n",
    "        yield np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.950504302978516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tmp = time.time()\n",
    "batchdata = next(data_gen(batch_size=128))\n",
    "print(time.time() - tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
